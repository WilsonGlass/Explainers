{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897e66b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import util\n",
    "from model import MultiLogisticRegressionModel\n",
    "import os\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display\n",
    "\n",
    "from omnixai.data.image import Image\n",
    "from omnixai.explainers.vision import L2XImage\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ef1e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def custom_cross_entropy_loss(input, target):\n",
    "    target = target.long()\n",
    "    return nn.CrossEntropyLoss()(input, target)\n",
    "\n",
    "def multi_logistic_predict_function(images):\n",
    "    \"\"\"\n",
    "    images: a list (or array) of omnixai.data.image.Image\n",
    "    returns: a numpy array of shape [N, 10], each row is a softmax probability distribution\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for im in images:\n",
    "        # Convert image to numpy array with shape (28, 28)\n",
    "        x_2d = im.to_numpy().astype(float)\n",
    "        probs = model.hypothesis(x_2d)\n",
    "        preds.append(probs)\n",
    "    return np.array(preds)\n",
    "\n",
    "\n",
    "train_data = util.get_dataset(\"mnist_train\")\n",
    "test_data = util.get_dataset(\"mnist_test\")\n",
    "\n",
    "train_arrays = np.array(train_data.xs)\n",
    "test_arrays = np.array(test_data.xs)\n",
    "\n",
    "train_labels = np.array(train_data.ys, dtype=np.int64)\n",
    "test_labels = np.array(test_data.ys, dtype=np.int64)\n",
    "\n",
    "train_imgs = Image(train_arrays, batched=True)\n",
    "test_imgs = Image(test_arrays, batched=True)\n",
    "\n",
    "num_features = 28 * 28\n",
    "num_classes = 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = MultiLogisticRegressionModel(\n",
    "    num_features=num_features,\n",
    "    num_classes=num_classes,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d8c0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.train(train_data, evalset=test_data)\n",
    "\n",
    "explainer = L2XImage(\n",
    "    training_data=train_imgs,\n",
    "    predict_function=multi_logistic_predict_function,\n",
    "    loss_function=custom_cross_entropy_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee55ba2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "explained_imgs_list = []\n",
    "for i in range(10):\n",
    "    file_path = os.path.join(\"mnist_png\", \"explained_imgs\", f\"{i}.png\")\n",
    "    img = PILImage.open(file_path).convert('L')\n",
    "    img_array = np.array(img).astype(float) / 255.0\n",
    "    explained_imgs_list.append(img_array)\n",
    "\n",
    "explained_imgs = Image(np.array(explained_imgs_list), batched=True)\n",
    "explanations = explainer.explain(explained_imgs)\n",
    "\n",
    "for idx in range(len(explained_imgs)):\n",
    "    display(explanations.ipython_plot(index=idx))\n",
    "predictions = multi_logistic_predict_function(explained_imgs)\n",
    "print(\"Predicted probabilities for the custom images:\\n\", predictions)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
